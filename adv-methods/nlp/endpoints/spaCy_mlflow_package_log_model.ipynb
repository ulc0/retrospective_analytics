{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4f7b288-6885-45f1-916d-261ebb463dde",
     "showTitle": false,
     "title": ""
    },
    "colab_type": "text",
    "id": "QdRNGb5ZN9UN"
   },
   "source": [
    "## Testing spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d782ef13-ef79-4c4c-9d21-8a7298fa4a2e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "5297px3K5cpO",
    "outputId": "ccdcac6a-36de-49cb-b841-43df76fb2c82"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") #, disable=[\"tagger\", \"parser\"])\n",
    "textcat=nlp.create_pipe( \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\n",
    "nlp.add_pipe(text_cat, last=True)\n",
    "nlp.pipe_names\n",
    "\n",
    "text = 'That is the will of Parliament and the nation. The British Empire and the French Republic, linked together in their cause and in their need, will defend to the death their native soil, aiding each other like good comrades to the utmost of their strength. Even though large tracts of Europe and many old and famous States have fallen or may fall into the grip of the Gestapo and all the odious apparatus of Nazi rule, we shall not flag or fail. We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in Godâ€™s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.'\n",
    "\n",
    "t = nlp(text)\n",
    "for ent in t.ents:\n",
    "  print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e83722b-0cbf-4a58-bfcc-fec853f98428",
     "showTitle": false,
     "title": ""
    },
    "colab_type": "text",
    "id": "gRS1lCX-Oc41"
   },
   "source": [
    "## Saving model and doing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7494c6a-8635-42d1-806a-903d2cdf5582",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "537GbMTUldnm",
    "outputId": "0ca34258-ec00-4448-9a31-b96297a2e37b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "nlp_model_path = 'spacy-nlp-model'\n",
    "\n",
    "\n",
    "nlp.to_disk(nlp_model_path)\n",
    "\n",
    "for e in nlp(text).ents:\n",
    "  print(e.text, e.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d66da72-9af6-4e7a-8329-3e1cc3d36f68",
     "showTitle": false,
     "title": ""
    },
    "colab_type": "text",
    "id": "RbagM-U6OejU"
   },
   "source": [
    "## Load model and get same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba89c461-2bdd-49e9-8fe4-92b94b6fc09f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "q2kDQU-NsSdN",
    "outputId": "abe7f806-6235-4440-b82f-70379dbd69e6"
   },
   "outputs": [],
   "source": [
    "mod = spacy.load(nlp_model_path)\n",
    "for e in mod(text).ents:\n",
    "  print(e.text, e.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b3fc575-4240-4ba7-bd9b-19cb42f6ac15",
     "showTitle": false,
     "title": ""
    },
    "colab_type": "text",
    "id": "O-idEfl4GJM3"
   },
   "source": [
    "## Install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ec32df1-be9a-4198-a709-570aece7425c",
     "showTitle": false,
     "title": ""
    },
    "colab_type": "text",
    "id": "c40WgNAxGLbd"
   },
   "source": [
    "## Save SpacyWrapper model, load and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b3ad1b0-fcbf-4fdc-9caf-007d4f9bc727",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "zPo0LLlMnMaL",
    "outputId": "f6f6e94c-87a8-4b20-a477-102ee28dda54"
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pip\n",
    "\n",
    "# Create an `artifacts` dictionary that assigns a unique name to the saved XGBoost model file.\n",
    "# This dictionary will be passed to `mlflow.pyfunc.save_model`, which will copy the model file\n",
    "# into the new MLflow Model's directory.\n",
    "artifacts = {\n",
    "    \"nlp_model\": nlp_model_path\n",
    "}\n",
    "\n",
    "# Define the model class\n",
    "import mlflow.pyfunc\n",
    "class SpacyWrapper(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "\n",
    "    def load_context(self, context):\n",
    "        import spacy\n",
    "        self.nlp = spacy.load(context.artifacts[\"nlp_model\"])\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "      import json\n",
    "      def get_entities(text):\n",
    "        ents = self.nlp(text).ents\n",
    "        return [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in ents]\n",
    "      try:\n",
    "        ents = model_input.text.apply(get_entities)\n",
    "\n",
    "        return ents.apply(lambda s: json.dumps(s))\n",
    "      except TypeError:\n",
    "        return \"DataFrame must contain strings\"\n",
    "\n",
    "# Create a Conda environment for the new MLflow Model that contains the XGBoost library\n",
    "# as a dependency, as well as the required CloudPickle library\n",
    "import cloudpickle\n",
    "# Let's create our own conda environment\n",
    "conda_env = {\n",
    "    'channels': ['defaults', 'pytorch'],\n",
    "    'dependencies': [\n",
    "      f'python=3.6.9',\n",
    "      {\n",
    "          'pip':[\n",
    "            f'pip=={pip.__version__}',\n",
    "            f'mlflow=={mlflow.__version__}',\n",
    "            f'spacy=={spacy.__version__}',\n",
    "            f'cloudpickle=={cloudpickle.__version__}'\n",
    "          ]\n",
    "      }\n",
    "    ],\n",
    "    'name': 'mlflow-env-spacy'\n",
    "}\n",
    "\n",
    "# Save the MLflow Model\n",
    "mlflow_pyfunc_model_path = \"spacy_mlflow_pyfunc\"\n",
    "# remove pre-existing folder\n",
    "import shutil\n",
    "shutil.rmtree(mlflow_pyfunc_model_path)\n",
    "mlflow.pyfunc.save_model(\n",
    "        python_model=SpacyWrapper(),\n",
    "         artifacts=artifacts,\n",
    "         path=mlflow_pyfunc_model_path,\n",
    "        conda_env=conda_env)\n",
    "\n",
    "# Load the model in `python_function` format\n",
    "loaded_model = mlflow.pyfunc.load_model(mlflow_pyfunc_model_path)\n",
    "\n",
    "# Evaluate the model\n",
    "import pandas as pd\n",
    "test_predictions = loaded_model.predict(pd.DataFrame(data={'text':['What a beautiful day', 'That is the will of Parliament and the nation. The British Empire and the French Republic, linked together in their cause and in their need']}))\n",
    "print(test_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "spaCy_mlflow_package_log_model",
   "widgets": {}
  },
  "colab": {
   "name": "spaCy-mlflow-docker-flask.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
