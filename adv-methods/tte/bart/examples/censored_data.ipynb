{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f9d1932-ce88-40a3-9c10-64ef9c6b2457",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Censored Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83756923-51f4-4194-8155-14076d867784",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c852e8ad-18e0-47d0-b5ce-d5cdfe4fb8ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "rng = default_rng(1234)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf566564-bc92-4958-9599-3c3520cc8f66",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "[This example notebook on Bayesian survival\n",
    "analysis](http://docs.pymc.io/notebooks/survival_analysis.html) touches on the\n",
    "point of censored data. _Censoring_ is a form of missing-data problem, in which\n",
    "observations greater than a certain threshold are clipped down to that\n",
    "threshold, or observations less than a certain threshold are clipped up to that\n",
    "threshold, or both. These are called right, left and interval censoring,\n",
    "respectively. In this example notebook we consider interval censoring.\n",
    "\n",
    "Censored data arises in many modelling problems. Two common examples are:\n",
    "\n",
    "1. _Survival analysis:_ when studying the effect of a certain medical treatment\n",
    "   on survival times, it is impossible to prolong the study until all subjects\n",
    "   have died. At the end of the study, the only data collected for many patients\n",
    "   is that they were still alive for a time period $T$ after the treatment was\n",
    "   administered: in reality, their true survival times are greater than $T$.\n",
    "\n",
    "2. _Sensor saturation:_ a sensor might have a limited range and the upper and\n",
    "   lower limits would simply be the highest and lowest values a sensor can\n",
    "   report. For instance, many mercury thermometers only report a very narrow\n",
    "   range of temperatures.\n",
    "\n",
    "This example notebook presents two different ways of dealing with censored data\n",
    "in PyMC3:\n",
    "\n",
    "1. An imputed censored model, which represents censored data as parameters and\n",
    "   makes up plausible values for all censored values. As a result of this\n",
    "   imputation, this model is capable of generating plausible sets of made-up\n",
    "   values that would have been censored. Each censored element introduces a\n",
    "   random variable.\n",
    "\n",
    "2. An unimputed censored model, where the censored data are integrated out and\n",
    "   accounted for only through the log-likelihood. This method deals more\n",
    "   adequately with large amounts of censored data and converges more quickly.\n",
    "\n",
    "To establish a baseline we compare to an uncensored model of the uncensored\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df406217-dfc1-4e28-aabd-80f7f08367a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Produce normally distributed samples\n",
    "size = 500\n",
    "true_mu = 13.0\n",
    "true_sigma = 5.0\n",
    "samples = rng.normal(true_mu, true_sigma, size)\n",
    "\n",
    "# Set censoring limits\n",
    "low = 3.0\n",
    "high = 16.0\n",
    "\n",
    "\n",
    "def censor(x, low, high):\n",
    "    x = copy(x)\n",
    "    x[x <= low] = low\n",
    "    x[x >= high] = high\n",
    "    return x\n",
    "\n",
    "\n",
    "# Censor samples\n",
    "censored = censor(samples, low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4120706-9bad-4add-a119-b104c60ee4f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize uncensored and censored data\n",
    "_, ax = plt.subplots(figsize=(10, 3))\n",
    "edges = np.linspace(-5, 35, 30)\n",
    "ax.hist(samples, bins=edges, density=True, histtype=\"stepfilled\", alpha=0.2, label=\"Uncensored\")\n",
    "ax.hist(censored, bins=edges, density=True, histtype=\"stepfilled\", alpha=0.2, label=\"Censored\")\n",
    "[ax.axvline(x=x, c=\"k\", ls=\"--\") for x in [low, high]]\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89a962bc-1034-4277-bcbd-53ba8fc57ad8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Uncensored Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3573826b-9665-416f-abfd-c4efa4d3e049",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def uncensored_model(data):\n",
    "    with pm.Model() as model:\n",
    "        mu = pm.Normal(\"mu\", mu=((high - low) / 2) + low, sigma=(high - low))\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=(high - low) / 2.0)\n",
    "        observed = pm.Normal(\"observed\", mu=mu, sigma=sigma, observed=data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81d38217-3eab-492a-9dba-c0a6e0bc7131",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We should predict that running the uncensored model on uncensored data, we will get reasonable estimates of the mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a11e4ea1-f6e9-475d-91ef-d3cade29861f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uncensored_model_1 = uncensored_model(samples)\n",
    "with uncensored_model_1:\n",
    "    trace = pm.sample(tune=1000, return_inferencedata=True)\n",
    "    az.plot_posterior(trace, ref_val=[true_mu, true_sigma], round_to=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d551ab7c-06ac-4363-a4e4-155e963be4cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "And that is exactly what we find. \n",
    "\n",
    "The problem however, is that in censored data contexts, we do not have access to the true values. If we were to use the same uncensored model on the censored data, we would anticipate that our parameter estimates will be biased. If we calculate point estimates for the mean and std, then we can see that we are likely to underestimate the mean and std for this particular dataset and censor bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "256e114e-66a6-46e9-b4d9-80250ce05b57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "np.mean(censored), np.std(censored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "723d7707-6fe7-41ab-8250-149440d907fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uncensored_model_2 = uncensored_model(censored)\n",
    "with uncensored_model_2:\n",
    "    trace = pm.sample(tune=1000, return_inferencedata=True)\n",
    "    az.plot_posterior(trace, ref_val=[true_mu, true_sigma], round_to=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94394efc-5d88-4af0-9365-9f15c728e996",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The figure above confirms this.\n",
    "\n",
    "## Censored data models\n",
    "\n",
    "The models below show 2 approaches to dealing with censored data. First, we need to do a bit of data pre-processing to count the number of observations that are left or right censored. We also also need to extract just the non-censored data that we observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aad43082-c136-46ce-af42-0c875a7109ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_right_censored = sum(censored >= high)\n",
    "n_left_censored = sum(censored <= low)\n",
    "n_observed = len(censored) - n_right_censored - n_left_censored\n",
    "uncensored = censored[(censored > low) & (censored < high)]\n",
    "assert len(uncensored) == n_observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd20e21c-10e3-40a5-a282-9a8ada5e3bbc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Model 1 - Imputed Censored Model of Censored Data\n",
    "\n",
    "In this model, we impute the censored values from the same distribution as the uncensored data. Sampling from the posterior generates possible uncensored data sets.\n",
    "\n",
    "This model makes use of [PyMC3's bounded variables](https://docs.pymc.io/api/bounds.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8007637-c21c-438a-9197-770cde7c7206",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as imputed_censored_model:\n",
    "    mu = pm.Normal(\"mu\", mu=((high - low) / 2) + low, sigma=(high - low))\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=(high - low) / 2.0)\n",
    "    right_censored = pm.Bound(pm.Normal, lower=high)(\n",
    "        \"right_censored\", mu=mu, sigma=sigma, shape=n_right_censored\n",
    "    )\n",
    "    left_censored = pm.Bound(pm.Normal, upper=low)(\n",
    "        \"left_censored\", mu=mu, sigma=sigma, shape=n_left_censored\n",
    "    )\n",
    "    observed = pm.Normal(\"observed\", mu=mu, sigma=sigma, observed=uncensored, shape=n_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e92293ba-0e04-4ce7-9ef7-7b05b321655c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with imputed_censored_model:\n",
    "    trace = pm.sample(return_inferencedata=True)\n",
    "    az.plot_posterior(trace, var_names=[\"mu\", \"sigma\"], ref_val=[true_mu, true_sigma], round_to=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37f528b2-b41f-4e7f-a6c0-c697c296be61",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can see that the bias in the estimates of the mean and variance (present in the uncensored model) have been largely removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9694149-d208-482b-90c3-0faa46f8f3be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Model 2 - Unimputed Censored Model of Censored Data\n",
    "\n",
    "In this model, we do not impute censored data, but instead integrate them out through the likelihood.\n",
    "\n",
    "The implementations of the likelihoods are non-trivial. See the [Stan manual](https://github.com/stan-dev/stan/releases/download/v2.14.0/stan-reference-2.14.0.pdf) (section 11.3 on censored data) and the [original PyMC3 issue on GitHub](https://github.com/pymc-devs/pymc3/issues/1833) for more information.\n",
    "\n",
    "This model makes use of [PyMC3's `Potential`](https://docs.pymc.io/api/model.html#pymc3.model.Potential)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db68205d-8cea-4717-948e-bb2ad6ced6e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import the log cdf and log complementary cdf of the normal Distribution from PyMC3\n",
    "from pymc3.distributions.dist_math import normal_lccdf, normal_lcdf\n",
    "\n",
    "\n",
    "# Helper functions for unimputed censored model\n",
    "def left_censored_likelihood(mu, sigma, n_left_censored, lower_bound):\n",
    "    \"\"\" Likelihood of left-censored data. \"\"\"\n",
    "    return n_left_censored * normal_lcdf(mu, sigma, lower_bound)\n",
    "\n",
    "\n",
    "def right_censored_likelihood(mu, sigma, n_right_censored, upper_bound):\n",
    "    \"\"\" Likelihood of right-censored data. \"\"\"\n",
    "    return n_right_censored * normal_lccdf(mu, sigma, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6576aa29-1b23-4b2a-b46b-1481bbcdfe2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as unimputed_censored_model:\n",
    "    mu = pm.Normal(\"mu\", mu=0.0, sigma=(high - low) / 2.0)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=(high - low) / 2.0)\n",
    "    observed = pm.Normal(\n",
    "        \"observed\",\n",
    "        mu=mu,\n",
    "        sigma=sigma,\n",
    "        observed=uncensored,\n",
    "    )\n",
    "    left_censored = pm.Potential(\n",
    "        \"left_censored\", left_censored_likelihood(mu, sigma, n_left_censored, low)\n",
    "    )\n",
    "    right_censored = pm.Potential(\n",
    "        \"right_censored\", right_censored_likelihood(mu, sigma, n_right_censored, high)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81cbb47a-7379-4760-8dc8-916cc80722e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "903f2690-c37c-4019-9b8b-b6988a4a620d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with unimputed_censored_model:\n",
    "    trace = pm.sample(tune=1000, return_inferencedata=True)\n",
    "    az.plot_posterior(trace, var_names=[\"mu\", \"sigma\"], ref_val=[true_mu, true_sigma], round_to=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adc5d5cd-7fc6-4ce5-9298-7dc450fb5efe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Again, the bias in the estimates of the mean and variance (present in the uncensored model) have been largely removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5b8372c-cccf-4276-a264-dfb602fa0265",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Discussion\n",
    "\n",
    "As we can see, both censored models appear to capture the mean and variance of the underlying distribution as well as the uncensored model! In addition, the imputed censored model is capable of generating data sets of censored values (sample from the posteriors of `left_censored` and `right_censored` to generate them), while the unimputed censored model scales much better with more censored data, and converges faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa7630b5-e129-4264-b748-b164f8f903b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Authors\n",
    "\n",
    "- Originally authored by [Luis Mario Domenzain](https://github.com/domenzain) on Mar 7, 2017.\n",
    "- Updated by [George Ho](https://github.com/eigenfoo) on Jul 14, 2018.\n",
    "- Updated by [Benjamin Vincent](https://github.com/drbenvincent) in May 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03af497b-04d9-4aba-82bf-b98d90d6a5cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p theano,xarray"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "censored_data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
