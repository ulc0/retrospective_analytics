{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d36cdca-04ce-4c75-ae39-cca60661da6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sksurv as sks\n",
    "import sksurv.preprocessing\n",
    "####import sksurv.metrics\n",
    "import sksurv.datasets\n",
    "###import sksurv.linear_model\n",
    "###import sksurv.ensemble\n",
    "\n",
    "from pathlib import Path\n",
    "#import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import scipy.stats as sp\n",
    "\n",
    "import pymc as pm\n",
    "import pymc_bart as pmb\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import mlflow as ml\n",
    "import shared.simsurv_func as ssf\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b821efa-df47-4471-89f7-fa8fa9a292d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc69b40b-3958-46b3-bf93-ed6dea7974f1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Objective\n",
    "Simulations of the cox proportional and non proportional survial models. \n",
    "Validation of bart pymc against cph model, rsf model.\n",
    "\n",
    "Validation metrics:\n",
    "    2 bool\n",
    "    5 bool\n",
    "    2 bool + 1 linear\n",
    "    complex combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023d6901-35be-47c0-99fc-fa7335b76c49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set experiment\n",
    "    # - each simulation parms is a new experiment\n",
    "\n",
    "# Simulation loop\n",
    "    # Creat run\n",
    "        # Simulate data\n",
    "        # log param alpha, lambda\n",
    "        # log param N\n",
    "        # log param T (of probabilites generated)\n",
    "        # log param x_info\n",
    "        # log param cen percent calculated\n",
    "        # log param status event calculated\n",
    "        # log param t_event mean\n",
    "        # log param t_event max\n",
    "        # log artif train dataset\n",
    "        # log artif plot curves\n",
    "\n",
    "        # model cph\n",
    "        # log metri coeff\n",
    "        # log metri exp(coef)\n",
    "        # log artif plot curves\n",
    "        # log model cph\n",
    "        \n",
    "        #  model rsf\n",
    "        # log artif plot curves\n",
    "        # log model resf\n",
    "\n",
    "        # tranform data long-form\n",
    "        # model bart\n",
    "        # transform to survival\n",
    "        # log artif plot curves\n",
    "        # log model bart\n",
    "\n",
    "        # get metrics rmse, bias\n",
    "        # log metri cph_rmse\n",
    "        # log metri cph_bias\n",
    "        # log metri rsf_rmse\n",
    "        # log metri rsf_bias\n",
    "        # log metri bart_rmse\n",
    "        # log metri bart_bias\n",
    "    \n",
    "    # End run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a5517b8-7afa-4433-88bc-0cc89247d810",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import sksurv as sks\n",
    "#import sksurv.preprocessing\n",
    "####import sksurv.metrics\n",
    "#import sksurv.datasets\n",
    "###import sksurv.linear_model\n",
    "###import sksurv.ensemble\n",
    "\n",
    "from pathlib import Path\n",
    "#import arviz as az\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import sklearn as skl\n",
    "#import scipy.stats as sp\n",
    "\n",
    "#import pymc as pm\n",
    "#import pymc_bart as pmb\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import mlflow \n",
    "import shared.simsurv_func as ssf\n",
    "#import subprocess\n",
    "OUTPUTS = \"outputs\"\n",
    "# LAMBDA = \"np.exp(2 + 0.4*(x_mat[:,0] + x_mat[:,1]))\"\n",
    "TRAIN_CSV = \"outputs/train.csv\"\n",
    "RBART_CSV = \"outputs/rbart_surv.csv\"\n",
    "N = 500\n",
    "# T = 30\n",
    "run= ml.start_run(run_name=\"test6\") \n",
    "run_info = ml.active_run()\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# Simulate data\n",
    "\n",
    "def sim_surv(N=100, \n",
    "            x_vars = 1, \n",
    "            lambda_f=None, \n",
    "            a=2, \n",
    "            alpha_f = None, \n",
    "            seed=999, \n",
    "            cens_ind = True,\n",
    "            cens_scale = 20,\n",
    "            err_ind = False):\n",
    "    # np.random.seed(seed)\n",
    "\n",
    "    x_mat = np.zeros((N, x_vars))\n",
    "    for x in np.arange(x_vars):\n",
    "        x1 = sp.bernoulli.rvs(.5, size = N)\n",
    "        x_mat[:,x] = x1\n",
    "    # calculate lambda\n",
    "    \n",
    "    # set lambda\n",
    "    if lambda_f is None:\n",
    "        lmbda = np.exp(2 + 0.3*(x_mat[:,0] + x_mat[:,1]) + x_mat[:,2])\n",
    "    else:\n",
    "        lmbda = eval(lambda_f)\n",
    "    \n",
    "    # set alpha if specified\n",
    "    if alpha_f is None:\n",
    "        a = np.repeat(a, N)\n",
    "    else:\n",
    "        a = eval(alpha_f)\n",
    "\n",
    "    # add error\n",
    "    if err_ind:\n",
    "        error = sp.norm.rvs(0, .5, size = N)\n",
    "        lmbda=lmbda + error\n",
    "\n",
    "    \n",
    "    # get the event times\n",
    "    tlat = np.zeros(N)\n",
    "    for idx, l in enumerate(lmbda):\n",
    "        # generate event times \n",
    "        unif = np.random.uniform(size=1)\n",
    "        ev = lmbda[idx] * np.power((-1 * np.log(unif)), 1/a[idx])\n",
    "        tlat[idx] = ev\n",
    "\n",
    "    if cens_ind:\n",
    "        # censor\n",
    "        cens = np.ceil(np.random.exponential(size = N, scale = cens_scale))\n",
    "\n",
    "        # min cen and surv event\n",
    "        t_event  = np.minimum(cens, np.ceil(tlat))\n",
    "        status = (tlat <= cens) * 1\n",
    "    else:\n",
    "        cens=np.zeros(N)\n",
    "        t_event = np.ceil(tlat)\n",
    "        status = np.ones(N)\n",
    "    \n",
    "    # get max event time\n",
    "    T = int(t_event.max())\n",
    "    # get time series\n",
    "    t = np.linspace(0,T, T)\n",
    "\n",
    "    # get surv curve true\n",
    "    sv_mat = np.zeros((N, t.shape[0]))\n",
    "    for idx, l in enumerate(lmbda):\n",
    "        sv = np.exp(-1 * np.power((t/l), a[idx]))\n",
    "        sv_mat[idx,:] = sv\n",
    "        \n",
    "        \n",
    "\n",
    "    return sv_mat, x_mat, lmbda, a, tlat, cens, t_event, status, T\n",
    "\n",
    "\n",
    "X_VARS = 5\n",
    "ALPHA = 3\n",
    "ALPHA_F = \"1 + (1.5 * x_mat[:,0]) + x_mat[:,1]\"\n",
    "LAMBDA = \"np.exp(1 + .2*x_mat[:,0] + .3*x_mat[:,1] + 0.8*np.sin(x_mat[:,0] * x_mat[:,1]) + np.power((x_mat[:,2] - 0.5),2))\"\n",
    "CENS_SCALE = 60\n",
    "CENS_IND = False\n",
    "\n",
    "sv_mat, x_mat, lmbda, a, tlat, cens, t_event, status, T = ssf.sim_surv(\n",
    "                N=N, \n",
    "                # T=T,\n",
    "                x_vars=X_VARS,\n",
    "                a = ALPHA,\n",
    "                alpha_f = ALPHA_F,\n",
    "                lambda_f = LAMBDA,\n",
    "                cens_scale=CENS_SCALE,\n",
    "                cens_ind = CENS_IND,\n",
    "                err_ind = False)\n",
    "\n",
    "# log param alpha\n",
    "ml.log_param(\"alpha\", ALPHA)\n",
    "# log param labmda\n",
    "ml.log_param(\"lambda\", LAMBDA)\n",
    "# log param N\n",
    "ml.log_param(\"N\", N)\n",
    "# log param T (# timepoint probabilites generated)\n",
    "ml.log_param(\"T\", T)\n",
    "# log param X_VARS\n",
    "ml.log_param(\"X_VARS\", X_VARS)\n",
    "# log parm CENS_SCALE\n",
    "ml.log_param(\"CENS_SCALE\", CENS_SCALE)\n",
    "# log parm CENS_IND\n",
    "ml.log_param(\"CENS_IND\", CENS_IND)\n",
    "#####\n",
    "\n",
    "def get_x_info(x_mat):\n",
    "    x = np.unique(x_mat, axis=0, return_index=True, return_counts=True)\n",
    "    x_out, x_idx, x_cnt = x[0], x[1], x[2]\n",
    "    return x_out, x_idx, x_cnt\n",
    "\n",
    "# log param x_info\n",
    "x_out, x_idx, x_cnt = ssf.get_x_info(x_mat)\n",
    "try:\n",
    "    ml.log_param(\"X_INFO\", str(list(zip(x_out, x_cnt))))\n",
    "except:\n",
    "    print(\"error\")\n",
    "\n",
    "\n",
    "# log metric cen percent calculated\n",
    "# log metric status event calculated\n",
    "def get_status_perc(status):\n",
    "    out = status.sum()/status.shape[0]\n",
    "    cens = 1-out\n",
    "    return out, cens\n",
    "event_calc, cens_calc = ssf.get_status_perc(status)\n",
    "ml.log_metric(\"EVENT_PERC\", event_calc)\n",
    "ml.log_metric(\"CENS_PERC\", cens_calc)\n",
    "\n",
    "def get_event_time_metric(t_event):\n",
    "    t_mean = t_event.mean()\n",
    "    t_max = t_event.max()\n",
    "    return t_mean, t_max\n",
    "# log metric t_event mean\n",
    "# log metric t_event max\n",
    "t_mean, t_max = ssf.get_event_time_metric(t_event)\n",
    "ml.log_metric(\"T_EVENT_MEAN\", t_mean)\n",
    "ml.log_metric(\"T_EVENT_MAX\", t_max)\n",
    "\n",
    "def get_train_matrix(x_mat, t_event, status):\n",
    "    et = pd.DataFrame({\"status\": status, \"time\":t_event})\n",
    "    train = pd.concat([et, pd.DataFrame(x_mat)],axis=1)\n",
    "    return train\n",
    "# log artif train dataset\n",
    "train = ssf.get_train_matrix(x_mat, t_event, status)\n",
    "# train.to_csv(\"outputs/train.csv\")\n",
    "train.to_csv(TRAIN_CSV)\n",
    "ml.log_artifact(\"outputs/train.csv\")\n",
    "\n",
    "\n",
    "# log artif plot curves\n",
    "title = \"actual_survival\"\n",
    "ssf.plot_sv(x_mat, sv_mat, T, title=title, save = True, dir=OUTPUTS)\n",
    "ml.log_artifact(f\"{OUTPUTS}/{title}.png\")\n",
    "\n",
    "\n",
    "def get_y_sklearn(status, t_event):\n",
    "    y = np.array(list(zip(np.array(status, dtype=\"bool\"), t_event)), dtype=[(\"Status\",\"?\"),(\"Survival_in_days\", \"<f8\")])\n",
    "    return y\n",
    "\n",
    "# get sklearn components\n",
    "y_sk = ssf.get_y_sklearn(status, t_event)\n",
    "x_sk = train.iloc[:,2:]\n",
    "\n",
    "######################################################################################\n",
    "# model cph\n",
    "cph = sksurv.linear_model.CoxPHSurvivalAnalysis()\n",
    "cph.fit(x_sk, y_sk)\n",
    "# log metri coeff\n",
    "for i in np.arange(len(cph.coef_)):\n",
    "    ml.log_metric(f\"cph_coef_{i}\", cph.coef_[i])\n",
    "    # log metri exp(coef)\n",
    "    ml.log_metric(f\"cph_exp_coef_{i}\", np.exp(cph.coef_[i]))\n",
    "# predic cph\n",
    "cph_surv = cph.predict_survival_function(pd.DataFrame(x_out))\n",
    "\n",
    "# get plotable data\n",
    "# cph_sv_val = [sf(np.arange(T)) for sf in cph_surv]\n",
    "cph_sv_t = cph_surv[0].x\n",
    "cph_sv_val = [sf(cph_sv_t) for sf in cph_surv]\n",
    "cph_sv_t = np.concatenate([np.array([0]), cph_sv_t])\n",
    "cph_sv_val = [np.concatenate([np.array([1]), sv]) for sv in cph_sv_val]\n",
    "\n",
    "# log artif plot curves\n",
    "title = \"cph_surv_pred\"\n",
    "ssf.plot_sv(x_mat, cph_sv_val, t=cph_sv_t, title = title, save=True, dir=\"outputs\")\n",
    "ml.log_artifact(f\"outputs/{title}.png\")\n",
    "# log model cph\n",
    "# idk how to do\n",
    "\n",
    "###################################################################################\n",
    "#  model rsf\n",
    "rsf = sksurv.ensemble.RandomSurvivalForest(\n",
    "    n_estimators=1000, min_samples_split=100, min_samples_leaf=15, n_jobs=-1, random_state=20\n",
    ")\n",
    "rsf.fit(x_sk, y_sk)\n",
    "# predict rsf\n",
    "rsf_surv = rsf.predict_survival_function(pd.DataFrame(x_out))\n",
    "# get plotable predictions\n",
    "# rsf_sv_val = [sf(np.arange(T)) for sf in rsf_surv]\n",
    "rsf_sv_t = rsf_surv[0].x\n",
    "rsf_sv_val = [sf(rsf_sv_t) for sf in rsf_surv]\n",
    "rsf_sv_t = np.concatenate([np.array([0]), rsf_sv_t])\n",
    "rsf_sv_val = [np.concatenate([np.array([1]), sv]) for sv in rsf_sv_val]\n",
    "# log artif plot curves\n",
    "title = \"rsf_surv_pred\"\n",
    "ssf.plot_sv(x_mat, rsf_sv_val, t=rsf_sv_t, title=title, save=True, dir=\"outputs\")\n",
    "ml.log_artifact(f\"outputs/{title}.png\")\n",
    "# log model resf\n",
    "\n",
    "################################################################################\n",
    "# BART\n",
    "M = 200 # number of trees\n",
    "DRAWS = 200\n",
    "TUNE = 200\n",
    "CORES = 4\n",
    "ml.log_param(\"n_tree\", M)\n",
    "ml.log_param(\"draws\", DRAWS)\n",
    "ml.log_param(\"tune\", TUNE)\n",
    "\n",
    "# tranform data long-form\n",
    "b_tr_t, b_tr_delta, b_tr_x = ssf.surv_pre_train2(x_sk, y_sk)\n",
    "# b_te_t, b_te_x = surv_pre_test(x_sk, y_sk)\n",
    "b_te_x = ssf.get_bart_test(x_out, np.unique(b_tr_t))\n",
    "off = sp.norm.ppf(np.mean(b_tr_delta))\n",
    "# model bart\n",
    "  \n",
    "with pm.Model() as bart:\n",
    "    x_data = pm.MutableData(\"x\", b_tr_x)\n",
    "    f = pmb.BART(\"f\", X=x_data, Y=b_tr_delta, m=M)\n",
    "    z = pm.Deterministic(\"z\", f + off)\n",
    "    mu = pm.Deterministic(\"mu\", pm.math.invprobit(z))\n",
    "    y_pred = pm.Bernoulli(\"y_pred\", p=mu, observed=b_tr_delta, shape=x_data.shape[0])\n",
    "    bdata = pm.sample(random_seed=2, draws=200, tune = 200, cores=4)\n",
    "\n",
    "with bart:\n",
    "# pm.set_data({\"x\":pd.DataFrame(test_x), \"off\":off_test})\n",
    "    pm.set_data({\"x\":pd.DataFrame(b_te_x)})\n",
    "    pp = pm.sample_posterior_predictive(bdata, var_names = [\"y_pred\", \"f\", \"z\", \"mu\"])\n",
    "\n",
    "# transform to survival\n",
    "bart_sv_fx = ssf.get_sv_fx(pp, x_out)\n",
    "# bart_svt\n",
    "bart_sv_t = np.unique(b_tr_t)\n",
    "\n",
    "# add a time 0 with prob 1 \n",
    "bart_sv_t = np.concatenate([np.array([0]), bart_sv_t])\n",
    "bart_sv_val = [np.concatenate([np.array([1]), sv]) for sv in bart_sv_fx]\n",
    "\n",
    "# log artif plot curves\n",
    "title = \"bart_surv_pred\"\n",
    "ssf.plot_sv(x_mat, bart_sv_val, t=bart_sv_t, title=title, save=True, dir=\"outputs\")\n",
    "ml.log_artifact(f\"outputs/{title}.png\")\n",
    "# log model bart /idk how to do\n",
    "\n",
    "# get metrics rmse, bias\n",
    "rsf_rmse, rsf_bias, t_quant = ssf.get_metrics( f_t = rsf_sv_val, f = sv_mat[x_idx], T = rsf_sv_t[rsf_sv_t <T])\n",
    "\n",
    "cph_rmse, cph_bias, t_quant = ssf.get_metrics( f_t = cph_sv_val, f = sv_mat[x_idx], T = cph_sv_t[cph_sv_t < T])\n",
    "\n",
    "bart_rmse, bart_bias, t_quant = ssf.get_metrics(f_t = bart_sv_val, f = sv_mat[x_idx], T = bart_sv_t[bart_sv_t < T])\n",
    "\n",
    "# log metri cph_rmse\n",
    "# log metri cph_bias\n",
    "# log metri rsf_rmse\n",
    "# log metri rsf_bias\n",
    "# log metri bart_rmse\n",
    "# log metri bart_bias\n",
    "for i in np.arange(rsf_rmse.shape[1]):\n",
    "    ml.log_metric(f\"rmse_rsf_{i}\", rsf_rmse[0,i])\n",
    "    ml.log_metric(f\"rmse_cph_{i}\", cph_rmse[0,i])\n",
    "    ml.log_metric(f\"rmse_bart_{i}\", bart_rmse[0,i])\n",
    "    ml.log_metric(f\"bias_rsf_{i}\", rsf_bias[0,i])\n",
    "    ml.log_metric(f\"bias_cph_{i}\", cph_bias[0,i])\n",
    "    ml.log_metric(f\"bias_bart_{i}\", bart_bias[0,i])\n",
    "\n",
    "############################################################################\n",
    "# run the rbart subprocess\n",
    "p1 = subprocess.Popen([\n",
    "    \"Rscript\",\n",
    "    \"surv_sim_function.R\",\n",
    "    TRAIN_CSV,\n",
    "    RBART_CSV\n",
    "    ])\n",
    "p1.wait()\n",
    "\n",
    "# get Rbart data\n",
    "rb_mat, rb_x, rb_idx, rb_sv_t, rb_sv_val = ssf.get_rbart_data(RBART_CSV)\n",
    "# get survival plot\n",
    "title = \"rbart_surv_pred\"\n",
    "ssf.plot_sv(rb_mat, rb_sv_val, t=rb_sv_t, title=title, show = False, save=True, dir=\"outputs\")\n",
    "ml.log_artifact(f\"outputs/{title}.png\")\n",
    "\n",
    "# get metrics for rb\n",
    "rb_rmse, rb_bias, t_quant = ssf.get_metrics( f_t = rb_sv_val, f = sv_mat[x_idx], T = rb_sv_t)\n",
    "\n",
    "# log metrics\n",
    "for i in np.arange(rb_rmse.shape[1]):\n",
    "    ml.log_metric(f\"rmse_rb_{i}\", rb_rmse[0,i])\n",
    "    ml.log_metric(f\"bias_rb_{i}\", rb_bias[0,i])\n",
    "\n",
    "\n",
    "# log mean metrics for all\n",
    "ml.log_metric(\"rmse_mean_cph\", cph_rmse.mean())\n",
    "ml.log_metric(\"bias_mean_cph\", cph_bias.mean())\n",
    "ml.log_metric(\"rmse_mean_rsf\", rsf_rmse.mean())\n",
    "ml.log_metric(\"bias_mean_rsf\", rsf_bias.mean())\n",
    "ml.log_metric(\"rmse_mean_bart\", bart_rmse.mean())\n",
    "ml.log_metric(\"bias_mean_bart\", bart_bias.mean())\n",
    "ml.log_metric(\"rmse_mean_rb\", rb_rmse.mean())\n",
    "ml.log_metric(\"bias_mean_rb\", rb_bias.mean())\n",
    "\n",
    "\n",
    "# log all plots of metrics\n",
    "title=\"RMSE\"\n",
    "ssf.plot_metrics(t_quant, T, rsf_rmse[0], cph_rmse[0], bart_rmse[0], rb_rmse[0], title, \"outputs\")\n",
    "ml.log_artifact(f\"outputs/{title}.png\")\n",
    "title=\"BIAS\"\n",
    "ssf.plot_metrics(t_quant, T, rsf_bias[0], cph_bias[0], bart_bias[0], rb_bias[0], title, \"outputs\")\n",
    "ml.log_artifact(f\"outputs/{title}.png\")\n",
    "\n",
    "# End run (defaults when using with/ block)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "surv_sim_1_ml",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
