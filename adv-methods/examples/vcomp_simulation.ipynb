{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32b37b3c-97e4-4b41-95f5-41c4ee074c36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Mixed models with variance components\n",
    "------------------------------------------\n",
    "\n",
    "This notebook demonstrates fitting mixed linear models with variance components in Statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7514a3d1-d2ef-4bba-8bcb-f5f198337798",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "586699e3-0d23-4723-90ed-7b3c82985958",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Specifying models\n",
    "\n",
    "Statsmodels MixedLM is group-based, meaning that the data are partitioned into specified, disjoint groups, and all random effects are independently realized across the groups.  Crossed random effects that are shared over the groups are not supported at present.\n",
    "\n",
    "The interface to `MixedLM` involves three types of effects.  \n",
    "\n",
    "* Fixed effects are coefficients that multiply the columns of a design matrix (`exog_fe`), just like in a traditional linear model.\n",
    "\n",
    "* Random effects are random terms that are arbitrarily correlated with each other.  There must be the same number of random terms for every group.  For example, if there are two random effects `r1` and `r2`, then the random effects design matrix `exog_re` must have two columns `v1` and `v2`.  The linear combination `r1*v1 + r2*v2` is an additive term contributing to `endog`.  Note that `r1` and `r2` are random variables with mean zero that are realized independently for each group.  There are three unknown parameters describing this part of the model: variance parameters for `r1` and `r2`, and a parameter for the covariance between `r1` and `r2`.\n",
    "\n",
    "* Variance components are random terms with mean zero that are always uncorrelated with each other.  Each variance component has a single parameter associated with it defining its variance.  There may be multiple independent realizations of each variance component within a group, and different groups can have differing numbers of realizations of each variance component.  \n",
    "\n",
    "One use case for variance components is nested random intercepts.  Suppose the top-level group is the school that a student attends, and there are dfferent classrooms within each school.  The random intercepts for the classrooms should be independent of each other, but all have the same variance.  The number of classrooms per school may vary. Extending this idea, a variance component could represent a random coefficient for an observed variable (like the score on a previous test).  If these slopes vary by classroom then they can be modeled as variance components. \n",
    "\n",
    "The standard array-based interface for specifying variance components is somewhat complex, it is somewhat easier to use formulas.  We will first describe the array-based interface first and then describe the formula interface below.  \n",
    "\n",
    "Suppose we have two variance components, one a random intercept for classrooms, and one a random coefficient for the previous year's test score, which we want to allow to vary either by school or by classroom.  We pass to `MixedLM` a dictionary `vc` containing the design information for the variance components.  The keys for `vc` are names for the variance components, here 'classroom' and 'prior_score'.  \n",
    "\n",
    "The classroom effect design information for group 0 is located in ``vc['classroom'][0]``.  It could be an array such as:\n",
    "\n",
    "```\n",
    "1 0 0\n",
    "1 0 0\n",
    "1 0 0\n",
    "0 1 0\n",
    "0 1 0\n",
    "0 1 0\n",
    "0 0 1\n",
    "0 0 1\n",
    "0 0 1\n",
    "```\n",
    "\n",
    "Note that this array has three columns, indicating that there are three classrooms in school 0.  The columns are indicator vectors reflecting which student attends each school.  Note that since different schools could have different numbers of classrooms, these design matrices may have differing numbers of columns.  Regardless of the number of columns, all random coefficients multiplying the columns of these matrices will have the same variance parameter.\n",
    "\n",
    "The second variance component is for the prior year's test score.  If we want this variable to have a random coefficient that varies by school but not by classroom, it could be included in `exog_re`, rather than treating it as a variance component (this would result in a random slope for the prior test score that is correlated with other random terms in the model).  Alternatively, the prior test score could be modeled using a variance component.  The resulting random terms would be uncorrelated with any other random terms in the model.  If we set ``vc['priortest'][0]`` equal to a column vector of prior test score, like\n",
    "\n",
    "```\n",
    "76\n",
    "89\n",
    "56\n",
    "77\n",
    "94\n",
    "85\n",
    "83\n",
    "78\n",
    "82\n",
    "```\n",
    "\n",
    "then the random coefficient for the prior test score is the same for everyone in a given school.  If instead we set ``vc['priortest'][0]`` to\n",
    "\n",
    "```\n",
    "76  0  0\n",
    "89  0  0\n",
    "56  0  0\n",
    "0  77  0\n",
    "0  94  0\n",
    "0  85  0\n",
    "0   0 83\n",
    "0   0 78\n",
    "0   0 82\n",
    "```\n",
    "\n",
    "then each classroom has its own slope for the prior test scores.  These slopes are independent of each other but all have have the same variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cb7df39-dd97-43b4-a6c1-949c044a8394",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The following function simulates data following the example discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ea05287-ff50-4c88-af32-165ec0974276",
     "showTitle": false,
     "title": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(n):\n",
    "    \n",
    "    # The fixed effects design matrix\n",
    "    exog = np.random.normal(size=(n, 3))\n",
    "\n",
    "    # A random intercept and two covariates with random slopes.\n",
    "    exog_re = np.random.normal(size=(n, 2))\n",
    "    exog_re[:, 0] = 1\n",
    "    \n",
    "    # Group labels for two levels of nested subgroups.\n",
    "    exog_vc = np.empty((n, 2))\n",
    "    exog_vc[:, 0] = np.kron(np.arange(n / 4), np.ones(4)) # Classroom membership\n",
    "    exog_vc[:, 0] = exog_vc[:, 0] % 4                     # Restart labels in each school\n",
    "    exog_vc[:, 1] = np.random.normal(size=n)              # Prior test score\n",
    "    \n",
    "    # All groups have 16 observations\n",
    "    groups = np.kron(np.arange(n / 16), np.ones(16))\n",
    "    \n",
    "    # Build up the error term\n",
    "    errors = 0.\n",
    "    \n",
    "    # Add random effects to the error term\n",
    "    exog_coeffs = np.random.normal(size=(n / 16, 2))\n",
    "    exog_coeffs = np.kron(exog_coeffs, np.ones((16, 1)))\n",
    "    errors += (exog_re * exog_coeffs).sum(1)\n",
    "    \n",
    "    # True variance component parameters\n",
    "    vcomp = [2, 5]\n",
    "    \n",
    "    # Add variance components to the error term\n",
    "    for j in 0,1:\n",
    "        for k in range(4): # 4 classrooms per school\n",
    "            x = (exog_vc[:, 0] == k)\n",
    "            if j == 1:\n",
    "                x = x * exog_vc[:, 1] # prior test score for one classroom\n",
    "            rt = np.random.normal(size=n/16) * np.sqrt(vcomp[j])\n",
    "            rt = np.kron(rt, np.ones(16))\n",
    "            errors += rt * x \n",
    "    \n",
    "    # Add iid 'residual' errors to the error term\n",
    "    errors += np.random.normal(size=n)\n",
    "    \n",
    "    endog = np.dot(exog, np.r_[0, 1, -2])\n",
    "    endog += errors\n",
    "    \n",
    "    return endog, groups, exog, exog_re, exog_vc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "537349e0-7290-473e-9c00-7da9e9f32345",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Next we generate data, and take a look at what we have in `exog_vc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebabb4ed-d316-4197-8ce1-abcd7125f423",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endog, groups, exog, exog_re, exog_vc = gen_data(1600)\n",
    "\n",
    "print(exog_vc[0:16, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72063fb0-a5ce-4c08-ac76-257deb350446",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The `exog_vc` data needs further processing.  We use Patsy to help with this, as shown below.  Note that when constructing a subgroup random intercept or slope, you should not include an intercept in the model (by using \"0 +\" in the formula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f297ca5-bb10-4db3-ba6a-f61f879be16c",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(exog_vc, columns=(\"classroom\", \"priortest\"))\n",
    "\n",
    "vca = patsy.dmatrix(\"0 + C(classroom)\", df, return_type='dataframe')\n",
    "vcb = patsy.dmatrix(\"0 + C(classroom):priortest\", df, return_type='dataframe')\n",
    "\n",
    "vc = {\"classroom\": {}, \"priortest\": {}}\n",
    "for k in range(100):\n",
    "    ii = np.flatnonzero(groups == k)\n",
    "    vc[\"classroom\"][k] = np.asarray(vca.iloc[ii, :])\n",
    "    vc[\"priortest\"][k] = np.asarray(vcb.iloc[ii, :])\n",
    "\n",
    "print(vc[\"classroom\"][0])\n",
    "print(vc[\"priortest\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e94bbb30-0d26-48a9-a4cc-f5e855f98726",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now we can fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b760d0f7-bbdb-4fec-87a6-21adcffd0e74",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex = sm.add_constant(exog)\n",
    "model1 = sm.MixedLM(endog, ex, groups, exog_re=exog_re, exog_vc=vc)\n",
    "result1 = model1.fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b8439c6-dfdd-4854-99ad-c951a2a27250",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Next we fit the same model using formulas.  Note again that subgroup-level intercepts and slopes should not have overall intercepts, so use \"0 +\" in the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e42c8341-9f3f-4ec3-9a83-339345ec4601",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=range(len(endog)))\n",
    "df[\"y\"] = endog\n",
    "df[\"x1\"] = exog[:, 0]\n",
    "df[\"x2\"] = exog[:, 1]\n",
    "df[\"x3\"] = exog[:, 2]\n",
    "df[\"z1\"] = exog_re[:, 0]\n",
    "df[\"z2\"] = exog_re[:, 1]\n",
    "df[\"classroom\"] = exog_vc[:, 0]\n",
    "df[\"prior_test\"] = exog_vc[:, 1]\n",
    "df[\"groups\"] = groups\n",
    "\n",
    "vcf = {\"classroom\" : \"0 + C(classroom)\", \"prior_test\" : \"0 + C(classroom):prior_test\"}\n",
    "\n",
    "model2 = sm.MixedLM.from_formula(\"y ~ x1 + x2 + x3\", groups=\"groups\", re_formula=\"0 + z1 + z2\", vc_formula=vcf, data=df)\n",
    "result2 = model2.fit()\n",
    "print(result2.summary())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "vcomp_simulation",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  },
  "name": "2015-04-18-122513.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
